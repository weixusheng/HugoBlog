# 物联网概论 PART-9



物联网与大数据
<!--more-->

# 物联网与大数据
## 大数据概念
 - 无法在可承受的时间范围内用常规软件工具进行捕捉、管理和处理的数据集合
 - 是需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力
 - 海量、高增长和多样化的信息资产

## 数据特点
### 海量(Volume)
 - 物联网数据来源海量异构的感知设备,描述着物理世界对象的各种状态及变化
 - 海量感知设备
 - 海量节点
 - 传感器节点多数处于全时工作状态
 - 物联网数据由TB跃升到PB

### 多样(Variety)
 - 物联网应用范围广泛,在不同领域、不同行业面对不同类型、不同格式的数据,如网络日志、视频、图像、地理位置信息
 - 物联网数据有明显的颗粒性,数据通常是多维的甚至是高维的。集成多个感知设备,同时感知某一对象的多个属性
 - 物联网数据具有多源异构的特征。数据多来源于不同的传感器,由于感知对象和感知目的的不同,这些设备产生的数据多具有不同的结构和语义

### 高速(Velocity)
 - 数据增长速度快,处理速度也快,时效性要求高。
 - 物联网与真实世界直接关联,很多情况下需要实时访问控制,同时需要更高的数据传输速率来支持这种实时性
 - 决策,检索,通信都需要高速(如检索新闻,如智能交通)

### 真实(Veracity)
 - 指数据的质量和保真性。大数据环境下的数据最好具有较高的信噪比。

### 价值(Value)
 - 即低价值密度。随着数据量的增长,数据中有意义的信息却没有成相应比例增长。而价值同时与数据的真实性和数据处理时间相关

### 大数据(5V)
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/1.png)

## 储存角度的划分
### 结构化数据
 - 指遵循一个标准的模式和结构(conform to adata model or schema),以二维表格的形式存储在关系型数据库里的行数据。结构化数据是先有结构、后产生数据。
 - 结构化数据简单的说,就是关系型数据库里的数据
 - 由于关系型数据库发展较为成熟,因此结构化数据的存储、分析方法也发展的较为全面,有大量的工具支持结构化数据分析,分析方法大部门以统计分析和数据挖掘为主。
 - 其中,关系型数据库(Relational Database)是创建在关系模型基础上的数据库,关系模型即二维表格模型,因此一个关系型数据库包括一些二维表且这些表之间的具有一定关联。关系型数据库可运用SQL语言通过固有键值提取相应信息。

### 非结构化数据
 - 是指不遵循统一的数据结构或模型的数据(如文本、图像、视频、音频等),不方便用二维逻辑表来表现。这部分数据在企业数据中占比大,且增长速率更快。
 - 非结构化数据更难被计算机理解,不能直接被处理或用SQL语句进行查询。非结构化数据常以二进制大型对象(BLOB,将二进制数据存储为一个单一个体的集合)形式,整体存储在关系型数据库中中;或存储在非关系型数据库中(NoSQL数据库)。其处理分析过程也更为复杂。
 - 半结构化数据,是指有一定的结构性,但本质上不具有关系性,介于完全结构化数据和完全非结构化数据之间的数据。
 - 它可以说是结构化数据的一种,但是结构变化很大。因此,为了了解数据的细节,不能将数据简单按照非结构化数据或结构化数据进行处理,需要特殊的存储(化解为结构化数据/用XML格式来组织)和处理技术。
 - 半结构化数据包含相关标记,用来分隔语义元素以及对记录和字段进行分层。因此,它也被称为自描述的结构(以树或者图的数据结构存储的数据)。先有数据,再有结构。两种常见的半结构化数据:XML文件和JSON文件。常见来源包括电子转换数据(EDI)文件、扩展表、RSS源、传感器数据。

# 物联网数据存储
## 特点
 - 海量存储空间;多源异构,数据的表达需要细致考虑
 - 支持多粒度分级存储和检索,改善资源利用率,提高资源获取率
 - 具有实时性的多维检测
 - 冗余数据需要压缩

## 满足的条件
 - 开放兼容。接口与交互协议必须便于物联网信息的发现,定位和获取;屏蔽接口的复杂性,兼容多源异构的物联网
 - 动态扩展。包括存储能力的动态扩展和数据结构动态可扩展。
 - 可靠高效。支持高并发性,具有高容错能力
 - 安全可信。

## 关系模型
### 特点
 - 每一列不可再分
 - 同一关系中属性(字段)不允许重名
 - 关系中不允许有完全相同的元组
 - 关系中任意交换两行位置不影响数据实际含义
 - 关系中任意交换两列位置不影响数据实际含义

# 关系数据库
1. 关系数据库是建立在关系模型基础上的数据库
    - 关系数据结构
    - 关系数据操作
    - 关系完整性约束
2. 目前实际使用的数据库系统大多是关系数据库
    - 关系数据库的相关概念:
    - 域(Domain):相同类型数据元素值的集合
    - 比如自然数集合、小写字母集合
    - 笛卡尔积:一组域D1, D2,..., Dn ,则笛卡尔乘积为
    - D1×D2×...×Dn ={( d1, d2,..., dn)| di ∈Di,i=1,2,...,n}
    - 元组(Tuple):
    - 笛卡尔乘积中每一个元素( d1, d2,..., dn)称为一个元组

## 笛卡尔积
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/2.png)
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/3.png)
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/4.png)

## 关系数据结构
 - <关系名>(属性名1,属性名2, ...... 属性名N)
 - shop(店名,地址,法人名,经营者名,电话)
 - fruit(水果名,价格,库存量,质量等级)
 - book(书名,著者名, 出版社,价格,页数,开本,ISBN,版本)
 - student(姓名,学号,性别,宿舍,电话)
 - 电话号码簿(电话号码,姓名)

## 关系数据操作
 - 查询操作:选择、投影、连接、并、交、差
 - 更新操作:增加、删除、修改数据的操作

## 常用三种关系运算
 - 选择运算
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/5.png)
 - 投影运算
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/6.png)
 - 连接运算
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/7.png)

## 完整性约束
**完整性约束=实体完整性+参照完整性+用户定义完整性**
 - 实体完整性主要指关系中关键字不为空且唯一
   - 例如公民数据表中身份证号不为空且唯一
 - 参照完整性指外码的删除,出现数据不完整性
   - 例如院系表中院系名称被删,导致学生表中院系取值错
 - 用户定义完整性指针对某一具体数据的约束条件
   - 教师表中教龄不能大于年龄

## SQL(structured query language)结构化查询语言
 - SQL(Structured Query Language),是目前关系数据库的标准结构化查询语言,1974年制订。目前流行的是SQL-92标准,它是由ANSI(美国国家标准局)颁布的。
 - 结构化查询语言包括三部分:
 - 数据定义语言DDL
 - 数据操纵语言DML
 - 数据控制语言DCL

# 非关系型数据库
 - 键值存储数据库
 - 列存储数据库
 - 文档型数据库
 - 图形数据库
 - 感知数据库
  
## 键值存储数据库
 - 使用一个哈希表,有一个特定的键值和一个指针指向特定的数据
 - 简单,容易部署
 - 针对部分值更新查询的效率低下

## 列存储数据库
 - 应对分布式存储的海量数据
 - 键指向多个列,列由列家族安排

## 文档型数据库
 - 数据是版本化的文档,半结构化的文档,如Json;
 - 和键值存储是类似的,是键值存储的升级版

## 图形数据库
 - 使用图形模型的数据库

## 感知数据库
 - 面向工业自动化,物联网等领域
 - 既可以进行关系数据管理,也可以在线存储实时特性的时序数据
 - 提供SQL标准接口,也提供实时数据的发布订阅,历史查询,历史数据分析等服务
 - 定位于满足企业级应用的数据库

# 本地文件系统和分布式文件系统
## 本地文件系统
物理存储资源直接连接在本地节点上,处理器通过系统总线可以直接访问
 - 物联网使用本地文件系统的方案较少,由于:
 - 功能有限,仅有基本的存储和索引功能,无法很好的支持大规模数据处理
 - 不同设备上的本地文件系统难以协同
 - 通常运行与独立的设备;容易丢失

## 分布式文件系统
通常使用分布式文件系统存储物联网数据
 - 建立于本地文件系统之上
 - 通过网络将若干节点相连
 - 逻辑上将独立的存储节点聚合为一个整体,统一管理
 - 提供并发处理;
 - 解决I/O瓶颈、空间动态扩展等问题

### 分布式优点
 - 简单配置即可轻松扩展集群
 - 并发控制,提高效率
 - 节点失效视为常态,容错性高;
 - 健全的数据恢复与备份,可靠性高;
 - 吞吐量大,适合大规模数据应用
 - 支持大数据处理工具

### GFS(Google File System)
 - GFS集群由一个主服务器(Master)和大量的块伺服器构成,并被许多客户(Client)访问。
 - 文件被分为固定大小的块,并分配一个全局唯一的块句柄(chunk-handle)标识。块伺服器将块做为本地文件存储,处于可靠性的考虑,一个块被复制到多个块伺服器上,默认是3个。
 - 主服务器维护数据所有的元数据,如块租约,孤儿块收集,块迁移等;主服务器通过心跳指令和块伺服器联系,传达指令,收集信息以及伺服器的状态。
 - 应用程序通过客户端使用文件系统,客户端和主服务器只交换元数据;数据通信直接和伺服器联系。

### FastDFS
 - 类似Google FS的开源轻量级分布式文件系统
 - 文件存储、同步、访问特别适合以文件为载体的在线服务(相册)
 - 系统内有Tracker server和Storage server2个角色
 - 不分块,直接存储文件

### TFS(Taobao File System)
 - 面向互联网服务,针对海量非结构化数据
 - 扁平化数据组织结构
 - 扩容
 - 提供海量小文件存储(每个文件通常不超过1M)

### MogileFS
 - 主要由调度器、数据库、存储节点和客户端组成
 - 2个服务进程 MogileFS Mogstored
 - 调度器是MogileFS的核心部分,负责复制、删除、查询、获取监控等多种任务的处理
 - 数据库存放MogileFS的元数据,由调度器来操作和管理
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/8.png)

### MooseFS
 - 容错的分布式文件系统
 - 一个支持随机读写的GFS实现
 - 由管理服务器、存储服务器、元数据备份服务器、客户端组成
 - 需要标准文件系统、较高的可扩展性顺序读写大量数据
 - 较少的随机写,可用性和数据一致性要求不高

### HDFS
 - HDFS是一个主从结构,
 - 一个名字节点,管理文件命名空间和客户端访问文件的主服务器,
 - 若干数据节点,通常是一个节点一个机器,它来管理对应节点的存储。HDFS对外开放文件命名空间并允许用户数据以文件形式存储
 - 内部机制是将一个文件分割成一个或多个块,这些块被存储在一组数据节点中。
 - 名字节点用来操作文件命名空间的文件或目录操作,如打开,关闭,重命名等等。它同时确定块与数据节点的映射。数据节点负责来自文件系统客户的读写请求。
 - 数据节点同时还要执行块的创建,删除,和来自名字节点的块复制指令

## HDFS实现过程
### 读取过程：
 - 客户端请求文件系统打开文件
 - DFS获取文件最开始的几个块的datanode地址。Namenode会根据网络拓扑结构决定返回哪些节点;客户端读取数据(调用read方法)
 - 第一个块读取完毕之后,寻找下一个块的最佳datanode,读取数据。如果有必要,会联系Namenode获取下一批块的节点信息这些寻址过程对客户端都是不可见的。
 - 数据读取完毕,客户端调用close方法关闭流对象
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/9.png)

在读数据过程中,如果与Datanode的通信发生错误,则会尝试从下一个最佳节点读取数据,并且记住该失败节点, 后续块的读取不会再连接该节点读取一个块之后,会进行检验和验证,如果块损坏,尝试从其他节点读取数据,并且将损坏的块汇报给Namenode。客户端连接哪个datanode获取数据,是由namenode来指导的,这样可以支持大量并发的客户端请求,namenode尽可能将流量均匀分布到整个集群。块的位置信息是存储在namenode的内存中,因此相应位置请求非常高效,不会成为瓶颈。

### 写入过程
 - 客户端写入,创建新的文件(块);
 - Namenode在文件系统的命名空间中创建一个新文件,此时该文件没有关联到任何block。 这个过程中,Namenode会做很多校验工作,例如是否已经存在同名文件,是否有权限,如果验证不通过,抛出异常到客户端。
 - 客户端写入数据的时候,分解为packets(数据包),并写入到一个数据队列中,请求Namenode分配新的block存放的数据节点。这些节点存放同一个Block的副本,构成一个管道。
 - 将packet写入到管道的第一个节点,第一个节点存放好packet之后,转发给下一个节点,下一个节点存放 之后继续往下传递。
 - 同时维护一个ack queue队列,等待来自datanode确认消息。当管道上的所有datanode都确认之后,packet从ack队列中移除。
 - 数据写入完毕,客户端close输出流。将所有的packet刷新到管道中,然后安心等待来自datanode的确认消息。全部得到确认之后告知Namenode文件是完整的。Namenode此时已经知道文件的所有Block信息(只需等待达到最小副本数要求,然后返回成功信息给客户端。
![img](https://tronwei-1254020584.cos.ap-beijing.myqcloud.com/IOT-9/10.png)

### HDFS副本存放策略
 - Namenode如何决定副本存在哪个Datanode?默认策略如下:
 - 第一个副本放在客户端相同的机器上,如果机器在集群之外,随机选择一个(但是会尽可能选择容量不是太慢或者当前操作太繁忙的)
 - 第二个副本随机放在不同于第一个副本的机架上。
 - 第三个副本放在跟第二个副本同一机架上,但是不同的节点上,满足条件的节点中随机选择。
 - 更多的副本在整个集群上随机选择,虽然会尽量避免太多副本在同一机架上。

### HDFS数据去重
 - 将旧数据的MD5值排序,新数据MD5值排序,运行MapReduce去重;
 - 使用MD5和SHA-1计算文件的哈希值,比较新旧数据的哈希值去重;
 - 将数据指纹(存储系统中文件块经过计算后的哈希索引)由存储控制器迁移到HDFS;生成数据指纹数据库,并在HDFS上永久存储该数据库 ;使用MapReduce从数据指纹记录集中筛选出重复记录,并将去重复后的数据指纹表保存回存储控制器。


